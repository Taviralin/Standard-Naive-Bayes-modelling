{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f3c9b0-6c9e-493f-9c56-9a0426b4d9c1",
   "metadata": {},
   "source": [
    "# CS361 Assignment 2\n",
    "### Name: Lin Lin\n",
    "### UPI: llin829\n",
    "----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6cd59-7f80-418a-863d-c53e4f43dde7",
   "metadata": {},
   "source": [
    "## Task 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25afb27e-7293-4bc1-833e-4002691202fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>the 4 202 353 bp genome of the alkaliphilic ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>the complete 1751377-bp sequence of the genome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>in 1992 we started assembling an ordered libra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>the aim of this study is to measure human mito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>the amino acid sequence of the spirulina maxim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class                                           abstract\n",
       "0   1     B  the 4 202 353 bp genome of the alkaliphilic ba...\n",
       "1   2     A  the complete 1751377-bp sequence of the genome...\n",
       "2   3     E  in 1992 we started assembling an ordered libra...\n",
       "3   4     E  the aim of this study is to measure human mito...\n",
       "4   5     B  the amino acid sequence of the spirulina maxim..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import math\n",
    "import string\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/heave/Desktop/CS361/A2/trg.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c85fe9c-8d47-45f1-b1d3-8d82c3e86018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the 4 202 353 bp genome of the alkaliphilic ba...\n",
       "1    the complete 1751377-bp sequence of the genome...\n",
       "2    in 1992 we started assembling an ordered libra...\n",
       "3    the aim of this study is to measure human mito...\n",
       "4    the amino acid sequence of the spirulina maxim...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['abstract']\n",
    "y = data['class']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0a964-2699-46b5-8196-77343238ce0d",
   "metadata": {},
   "source": [
    "#### Split data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d72a61a-eabc-4652-8297-97a5a40a86b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data set into training and test set\n",
    "split_index = int(len(data)*0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99249d9-f341-47c5-8b07-92aa2c0608b9",
   "metadata": {},
   "source": [
    "#### Count number of abstracts for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b4ef443-0bbe-4073-bdf8-409bf46acdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 100, 'B': 1296, 'E': 1703, 'V': 101}\n"
     ]
    }
   ],
   "source": [
    "def classify_and_count(X_train, y_train):\n",
    "    # Initialize the variable of number of class\n",
    "    number_of_classes = {'A': 0, 'B': 0, 'E': 0, 'V': 0}\n",
    "    \n",
    "    # Initialize the lists for each class\n",
    "    class_lists = {'A': [], 'B': [], 'E': [], 'V': []}\n",
    "    # Loop over the training data, tuple will be like (text, label)\n",
    "    for text, label in zip(X_train, y_train):\n",
    "        words = text.split()\n",
    "        if label in number_of_classes:\n",
    "            number_of_classes[label] += 1\n",
    "            class_lists[label].extend(words)\n",
    "    return number_of_classes, class_lists\n",
    "\n",
    "number_of_classes, class_lists = classify_and_count(X_train, y_train)\n",
    "print(number_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163e8bc-be71-4ee1-ac87-65aa9614fac8",
   "metadata": {},
   "source": [
    "#### Extract unique words for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "755dbdd2-97ec-4618-9608-74db48db2994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words per class: {'A': 2009, 'B': 11676, 'E': 20700, 'V': 3082}\n"
     ]
    }
   ],
   "source": [
    "# Extract uniques words for each class\n",
    "def extract_unique_words(class_lists):\n",
    "    unique_words = {}\n",
    "    for label, words in class_lists.items():\n",
    "        unique_words[label] = set(words)\n",
    "    return unique_words\n",
    "\n",
    "unique_words = extract_unique_words(class_lists)\n",
    "word_counts = {label: len(words) for label, words in unique_words.items()}\n",
    "print(\"Number of unique words per class:\", word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb63621-7734-49ea-94f9-8765847b3bcd",
   "metadata": {},
   "source": [
    "#### Extract unique words for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "668cd9b6-00f5-4447-90ce-2d78c1626200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words for all classes: 28541\n"
     ]
    }
   ],
   "source": [
    "all_unique_words = set()\n",
    "\n",
    "# Add words from each class to the all_unique_words set\n",
    "for words in unique_words.values():\n",
    "    all_unique_words.update(words)\n",
    "\n",
    "# Convert the set to a list if you need a list format\n",
    "all_unique_words_list = list(all_unique_words)\n",
    "print(\"Number of unique words for all classes:\", len(all_unique_words_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626ef3b-4e78-41c6-a219-1ac3a701389a",
   "metadata": {},
   "source": [
    "## Task 2 Implement the standard Naive Bayes base on text book algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f92cebb-f9fc-4a02-a9ea-5f395f807209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0.03125, 'B': 0.405, 'E': 0.5321875, 'V': 0.0315625}\n"
     ]
    }
   ],
   "source": [
    "def train_naive_bayes(X_train, y_train):\n",
    "    # Total number of documents\n",
    "    total_docs = len(X_train)\n",
    "    \n",
    "    # Calculate the prior probability for each class and add it to the class_priors dictionary\n",
    "    class_priors = {}\n",
    "    for label, count in number_of_classes.items():\n",
    "        class_priors[label] = count / total_docs\n",
    "    \n",
    "    # Total vocabulary size for Laplace smoothing\n",
    "    vocab_size = len(all_unique_words)\n",
    "    \n",
    "    # Calculate conditional probabilities P(wk|vj)\n",
    "    word_given_class = {}\n",
    "    for label, words in class_lists.items():\n",
    "        word_count = len(words)\n",
    "        word_freqs = Counter(words)\n",
    "        word_given_class[label] = {word: (word_freqs[word] + 1) / (word_count + vocab_size) for word in all_unique_words}\n",
    "    return class_priors, word_given_class, vocab_size\n",
    "    \n",
    "        \n",
    "class_priors, word_given_class, vocab_size = train_naive_bayes(X_train, y_train)\n",
    "print(class_priors) \n",
    "\n",
    "#first_key = list(word_given_class.keys())[0]\n",
    "#first_value = word_given_class[first_key]\n",
    "\n",
    "#print(\"First key:\", first_key)\n",
    "#print(\"First value:\", first_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc358b-5b0f-4818-9d5f-2cb8e0be9dcd",
   "metadata": {},
   "source": [
    "#### Make prediction on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cf4362ed-acc6-48ce-b2c6-625e80aa2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes classifier: 0.94625\n"
     ]
    }
   ],
   "source": [
    "def predict_naive_bayes(X_test, class_priors, word_given_class, vocab_size):\n",
    "    predictions = []\n",
    "    for doc in X_test:\n",
    "        words = doc.split()\n",
    "        doc_probs = {}\n",
    "        for class_label, priors in class_priors.items():\n",
    "            # Start with the log of the prior probability\n",
    "            doc_prob = math.log(priors)\n",
    "            for word in words:\n",
    "                if word in word_given_class[class_label]:\n",
    "                    doc_prob += math.log(word_given_class[class_label][word])\n",
    "                else:\n",
    "                    # Handle unseen words with smoothing\n",
    "                    doc_prob += math.log(1 / (sum(word_given_class[class_label].values()) + vocab_size))\n",
    "            doc_probs[class_label] = doc_prob\n",
    "        # Choose the class with the highest probability\n",
    "        predictions.append(max(doc_probs, key=doc_probs.get))\n",
    "    return predictions\n",
    "\n",
    "predictions = predict_naive_bayes(X_test, class_priors, word_given_class, vocab_size)\n",
    "\n",
    "def calculate_accuracy(predictions, y_test):\n",
    "    actual_labels = list(y_test)\n",
    "    \n",
    "    # Count correct predictions\n",
    "    correct_predictions = 0\n",
    "    for predicted, actual in zip(predictions, actual_labels):\n",
    "        if predicted == actual:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = calculate_accuracy(predictions, y_test)\n",
    "print(\"Accuracy of the Naive Bayes classifier:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa1e22-722b-4980-9c99-0360723bbed4",
   "metadata": {},
   "source": [
    "## Task 3 Improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12f452-523d-488a-98b9-2899fc84d644",
   "metadata": {},
   "source": [
    "#### Words Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "98e051e9-fff7-4243-a644-ed3595754754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Dictionary of terms to concatenate\n",
    "    concatenations = {\n",
    "        'homo sapiens': 'homo_sapiens',\n",
    "        'escherichia coli': 'escherichia_coli',\n",
    "        'human immunodeficiency virus': 'human_immunodeficiency_virus'\n",
    "    }\n",
    "    \n",
    "    # Replace each specified term with its concatenated version\n",
    "    for term, concat_term in concatenations.items():\n",
    "        text = text.replace(term, concat_term)\n",
    "    \n",
    "    return text\n",
    "\n",
    "X_train = [preprocess_text(text) for text in X_train]\n",
    "X_test = [preprocess_text(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868225e6-d868-4b9e-b581-0a53896dfd3b",
   "metadata": {},
   "source": [
    "#### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8b6fed0-d4f6-4cf2-8410-660979f228dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes classifier after removing stop words: 0.9450%\n"
     ]
    }
   ],
   "source": [
    "stop_words = set([\n",
    "    'the', 'a', 'an', 'of'])\n",
    "\n",
    "def remove_words(text):\n",
    "    # Convert to lowercase and remove punctuation\n",
    "    text = ''.join([char.lower() for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Remove stop words\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Example usage with X_train and X_test being defined previously\n",
    "X_train_processed = [remove_words(x) for x in X_train]\n",
    "X_test_processed = [remove_words(x) for x in X_test]\n",
    "\n",
    "\n",
    "number_of_classes, class_lists = classify_and_count(X_train_processed, y_train)\n",
    "class_priors, word_given_class, vocab_size = train_naive_bayes(X_train_processed, y_train)\n",
    "predictions = predict_naive_bayes(X_test_processed, class_priors, word_given_class, vocab_size)\n",
    "accuracy = calculate_accuracy(predictions, y_test)\n",
    "print(f\"Accuracy of the Naive Bayes classifier after removing stop words: {accuracy:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e35e12-de47-414f-9cc3-71e96a5b1752",
   "metadata": {},
   "source": [
    "#### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "832498d5-dfed-4a14-a09e-d1169d99541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                           abstract predicted_class\n",
      "0   1  in a previous work all three components of com...               A\n",
      "1   2  we compared morphology of two geographically c...               E\n",
      "2   3  factor xiii mr 320000 is a blood coagulation f...               E\n",
      "3   4  we report the characterisation of a human gene...               E\n",
      "4   5  fat tissue plays a critical role in the regula...               E\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"C:/Users/heave/Desktop/CS361/A2/tst.csv\")\n",
    "\n",
    "X_test_unseen = test_data['abstract']\n",
    "\n",
    "# Make predictions using the previously trained model\n",
    "predictions_unseen = predict_naive_bayes(X_test_unseen, class_priors, word_given_class, vocab_size)\n",
    "\n",
    "# Append predictions to the test data for reviewz\n",
    "test_data['predicted_class'] = predictions_unseen\n",
    "\n",
    "# Display the first few rows to verify the predictions\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68d612-40ce-4b96-b4ca-1dba520c2191",
   "metadata": {},
   "source": [
    "#### Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db15c367-2001-4378-a71e-5a370832e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'C:/Users/heave/Desktop/CS361/A2/predicted_classes_2.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV filez\n",
    "test_data.to_csv(output_file_path, index=False)  # Set index=False to avoid writing row indices in the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
